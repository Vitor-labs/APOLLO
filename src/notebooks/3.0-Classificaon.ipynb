{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "df = pd.read_csv(\"../data/interim/complete_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomKNNClassifier:\n",
    "    def __init__(self, metric: str = \"euclidean\"):\n",
    "        \"\"\"\n",
    "        Initialize KNN classifier with specified distance metric\n",
    "\n",
    "        Args:\n",
    "            metric: Distance metric ('euclidean' or 'cosine')\n",
    "        \"\"\"\n",
    "        self.metric = metric\n",
    "        self.scaler = StandardScaler()\n",
    "        self.label_encoder = LabelEncoder()\n",
    "\n",
    "    def preprocess_data(self, X: np.ndarray, y: list) -> tuple[np.ndarray, np.ndarray]:\n",
    "        \"\"\"\n",
    "        Preprocess the data by scaling features and encoding labels\n",
    "        \"\"\"\n",
    "        return self.scaler.fit_transform(X), self.label_encoder.fit_transform(y)\n",
    "\n",
    "    def cross_validate(\n",
    "        self, X: np.ndarray, y: np.ndarray, k: int, n_folds: int = 10\n",
    "    ) -> dict[str, float]:\n",
    "        \"\"\"\n",
    "        Perform k-fold cross-validation and calculate metrics\n",
    "        \"\"\"\n",
    "        skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "        metrics = defaultdict(list)\n",
    "\n",
    "        for train_idx, val_idx in skf.split(X, y):\n",
    "            knn = KNeighborsClassifier(n_neighbors=k, metric=self.metric).fit(\n",
    "                X[train_idx],\n",
    "                y[train_idx],\n",
    "            )\n",
    "\n",
    "            X_val, y_val = X[val_idx], y[val_idx]\n",
    "            y_pred = knn.predict(X_val)\n",
    "            y_prob = knn.predict_proba(X_val)\n",
    "\n",
    "            metrics[\"f1\"].append(f1_score(y_val, y_pred, average=\"weighted\"))\n",
    "            metrics[\"accuracy\"].append(accuracy_score(y_val, y_pred))\n",
    "            metrics[\"auc\"].append(roc_auc_score(y_val, y_prob, multi_class=\"ovr\"))\n",
    "            metrics[\"top_3_accuracy\"].append(\n",
    "                self.calculate_top_k_accuracy(y_prob, y_val, k=3)\n",
    "            )\n",
    "\n",
    "        return {key: np.mean(values) for key, values in metrics.items()}\n",
    "\n",
    "    @staticmethod\n",
    "    def calculate_top_k_accuracy(\n",
    "        y_prob: np.ndarray, y_true: np.ndarray, k: int\n",
    "    ) -> float:\n",
    "        \"\"\"\n",
    "        Calculate top-k accuracy\n",
    "        \"\"\"\n",
    "        top_k_predictions = np.argsort(y_prob, axis=1)[:, -k:]\n",
    "        correct = 0\n",
    "        for i, true_label in enumerate(y_true):\n",
    "            if true_label in top_k_predictions[i]:\n",
    "                correct += 1\n",
    "        return correct / len(y_true)\n",
    "\n",
    "\n",
    "def bayesian_optimize_knn(X: np.ndarray, y: np.ndarray, metric: str) -> Dict:\n",
    "    \"\"\"\n",
    "    Perform Bayesian optimization for KNN hyperparameters\n",
    "    \"\"\"\n",
    "\n",
    "    def objective(k):\n",
    "        k = int(k)\n",
    "        classifier = CustomKNNClassifier(metric=metric)\n",
    "        X_scaled, y_encoded = classifier.preprocess_data(X, y)\n",
    "        metrics = classifier.cross_validate(X_scaled, y_encoded, k)\n",
    "        return metrics[\"f1\"]  # Optimize for F1-score\n",
    "\n",
    "    optimizer = BayesianOptimization(\n",
    "        f=objective, pbounds={\"k\": (1, 15)}, random_state=42\n",
    "    )\n",
    "\n",
    "    optimizer.maximize(n_iter=20)\n",
    "\n",
    "    return {\n",
    "        \"best_k\": int(optimizer.max[\"params\"][\"k\"]),\n",
    "        \"best_score\": optimizer.max[\"target\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_metrics(euclidean_results: dict, cosine_results: dict) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Create a comparison DataFrame of metrics\n",
    "    \"\"\"\n",
    "    metrics = [\"accuracy\", \"f1\", \"auc\", \"top_3_accuracy\"]\n",
    "    return pd.DataFrame(\n",
    "        {\n",
    "            \"Euclidean\": [euclidean_results[m] for m in metrics],\n",
    "            \"Cosine\": [cosine_results[m] for m in metrics],\n",
    "        },\n",
    "        index=metrics,\n",
    "    )\n",
    "\n",
    "\n",
    "def plot_results(euclidean_results: dict, cosine_results: dict) -> None:\n",
    "    \"\"\"\n",
    "    Plot comparison of metrics between Euclidean and Cosine distance\n",
    "    \"\"\"\n",
    "    metrics = [\"accuracy\", \"f1\", \"auc\", \"top_3_accuracy\"]\n",
    "    x = np.arange(len(metrics))\n",
    "    width = 0.35\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    ax.bar(\n",
    "        x - width / 2, [euclidean_results[m] for m in metrics], width, label=\"Euclidean\"\n",
    "    )\n",
    "    ax.bar(x + width / 2, [cosine_results[m] for m in metrics], width, label=\"Cosine\")\n",
    "\n",
    "    ax.set_ylabel(\"Score\")\n",
    "    ax.set_title(\"Metric Comparison: Euclidean vs Cosine Distance\")\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(metrics)\n",
    "    ax.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "APOLLO-wWpZYX6t",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
